      <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>3D AI Assistant - Diagnostic Mode</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; -webkit-tap-highlight-color: transparent; }
    body { font-family: system-ui, sans-serif; background: #000; color: #fff; overflow: hidden; touch-action: none; }
    #canvas-container { position: fixed; top: 0; left: 0; width: 100%; height: 100%; }
    
    /* Diagnostic Log Overlay */
    #debug-log {
      position: fixed; top: 10px; left: 10px; width: 80%; max-height: 120px;
      background: rgba(0, 0, 0, 0.8); color: #0f0; font-family: monospace;
      font-size: 10px; z-index: 100; padding: 10px; border: 1px solid #0f0;
      border-radius: 8px; overflow-y: auto; pointer-events: none;
    }

    #controls { position: fixed; bottom: 30px; left: 50%; transform: translateX(-50%); z-index: 10; }
    button { 
      padding: 18px 40px; font-size: 16px; border: 2px solid #0ff; 
      background: rgba(0, 255, 255, 0.1); color: #0ff; border-radius: 50px; 
      cursor: pointer; backdrop-filter: blur(10px); font-weight: bold;
    }
    button.listening { background: rgba(255, 0, 100, 0.3); border-color: #f06; color: #f06; }
    
    #transcript { 
      position: fixed; bottom: 110px; left: 50%; transform: translateX(-50%); 
      width: 85%; text-align: center; font-size: 14px; text-shadow: 0 0 5px #000;
    }
  </style>
</head>
<body>
  <div id="debug-log">SYSTEM: Ready. Tap TALK to start.</div>
  <div id="canvas-container"></div>
  <div id="transcript">AI is waiting...</div>
  <div id="controls"><button id="talkBtn">TALK</button></div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>

  <script>
    // SECURE KEY MANAGEMENT
    const CONFIG = {
      deepgram: localStorage.getItem('dg_key') || '',
      groq: localStorage.getItem('groq_key') || ''
    };

    function log(msg) {
      const el = document.getElementById('debug-log');
      el.innerHTML += `<br>> ${msg}`;
      el.scrollTop = el.scrollHeight;
      console.log(msg);
    }

    // Initialize Keys if missing
    if (!CONFIG.deepgram || !CONFIG.groq) {
      const dg = prompt("Enter Deepgram API Key:");
      const gr = prompt("Enter Groq API Key:");
      if(dg && gr) {
        localStorage.setItem('dg_key', dg);
        localStorage.setItem('groq_key', gr);
        location.reload();
      }
    }

    let scene, camera, renderer, orb, eyes, state = 'idle';
    let socket, mediaRecorder;

    function initThree() {
      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      camera.position.z = 4;
      renderer = new THREE.WebGLRenderer({ antialias: false });
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.setPixelRatio(Math.min(window.devicePixelRatio, 1.5));
      document.getElementById('canvas-container').appendChild(renderer.domElement);

      const geometry = new THREE.IcosahedronGeometry(1, 4);
      const material = new THREE.ShaderMaterial({
        uniforms: {
          time: { value: 0 },
          audioLevel: { value: 0 },
          color: { value: new THREE.Color(0x00ffff) }
        },
        vertexShader: `
          uniform float time;
          uniform float audioLevel;
          varying vec3 vNormal;
          void main() {
            vNormal = normalize(normalMatrix * normal);
            vec3 pos = position + normal * (sin(position.y * 5.0 + time) * 0.05 + audioLevel * 0.5);
            gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
          }
        `,
        fragmentShader: `
          uniform vec3 color;
          varying vec3 vNormal;
          void main() {
            float fresnel = pow(1.0 - dot(vNormal, vec3(0,0,1)), 3.0);
            gl_FragColor = vec4(mix(color * 0.2, color, fresnel), 1.0);
          }
        `
      });
      orb = new THREE.Mesh(geometry, material);
      scene.add(orb);
      log("3D Scene Initialized.");
    }

let chunks = [];

async function startListening() {
  log("Starting Recorder (Buffer Mode)...");
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    state = 'listening';
    orb.material.uniforms.color.value.set(0x0066ff); // Blue
    document.getElementById('talkBtn').innerText = "STOP & SEND";
    document.getElementById('talkBtn').classList.add('listening');

    mediaRecorder = new MediaRecorder(stream);
    chunks = [];

    mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
    
    mediaRecorder.onstop = async () => {
      log("Processing recording...");
      const audioBlob = new Blob(chunks, { type: 'audio/webm' });
      await sendToDeepgram(audioBlob);
    };

    mediaRecorder.start();
    log("Listening... Tap STOP when done.");
  } catch (err) {
    log("Mic Error: " + err.message);
  }
}

async function sendToDeepgram(blob) {
  log("Uploading to Deepgram...");
  try {
    const response = await fetch('https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true', {
      method: 'POST',
      headers: {
        'Authorization': `Token ${CONFIG.deepgram}`,
        'Content-Type': 'audio/webm'
      },
      body: blob
    });

    const data = await response.json();
    const text = data.results?.channels[0]?.alternatives[0]?.transcript;
    
    if (text) {
      log("Heard: " + text);
      document.getElementById('transcript').innerText = "You: " + text;
      processGroq(text);
    } else {
      log("Deepgram couldn't understand.");
    }
  } catch (err) {
    log("Upload Failed. Check Wi-Fi.");
  }
}

// Update the button click handler to toggle
document.getElementById('talkBtn').onclick = () => {
  if (state === 'idle') {
    startListening();
  } else if (state === 'listening') {
    mediaRecorder.stop();
    state = 'thinking';
    orb.material.uniforms.color.value.set(0xaa00ff); // Purple
    document.getElementById('talkBtn').innerText = "TALK";
    document.getElementById('talkBtn').classList.remove('listening');
  }
};
        
        
        function stopListening() {
      state = 'thinking';
      orb.material.uniforms.color.value.set(0xaa00ff);
      document.getElementById('talkBtn').classList.remove('listening');
      if(mediaRecorder) mediaRecorder.stop();
      if(socket) socket.close();
    }

    async function processGroq(text) {
      log("Fetching Groq response...");
      try {
        const resp = await fetch('https://api.groq.com/openai/v1/chat/completions', {
          method: 'POST',
          headers: {'Authorization': `Bearer ${CONFIG.groq}`, 'Content-Type': 'application/json'},
          body: JSON.stringify({model: 'llama-3-8b-8192', messages: [{role: 'user', content: text}]})
        });
        const data = await resp.json();
        if(data.choices) {
          log("Groq Success.");
          speak(data.choices[0].message.content);
        } else {
          log("Groq API Key/Limit Error.");
        }
      } catch (e) {
        log("Groq Connection Failed.");
      }
    }

    function speak(text) {
      state = 'speaking';
      orb.material.uniforms.color.value.set(0x00ffaa);
      document.getElementById('transcript').innerText = "AI: " + text;
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.onstart = () => {
        const sync = setInterval(() => {
          if (!window.speechSynthesis.speaking) {
            clearInterval(sync);
            orb.material.uniforms.audioLevel.value = 0;
            state = 'idle';
            orb.material.uniforms.color.value.set(0x00ffff);
            return;
          }
          orb.material.uniforms.audioLevel.value = 0.1 + Math.random() * 0.4;
        }, 50);
      };
      window.speechSynthesis.speak(utterance);
    }

    function animate() {
      requestAnimationFrame(animate);
      orb.material.uniforms.time.value = Date.now() * 0.002;
      renderer.render(scene, camera);
    }

    document.getElementById('talkBtn').onclick = () => {
      if(state === 'idle') startListening();
    };

    window.addEventListener('resize', () => {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    });

    initThree();
    animate();
  </script>
</body>
</html>
